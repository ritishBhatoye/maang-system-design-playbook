# ðŸŽ¯ Cascading Failures (2026 MAANG Edition)

## 1. Why This Matters in Interviews

Cascading failures are the **root cause of major outages** at every major tech company. Interviewers test this to see if you can design resilient systems that fail gracefully.

---

## 2. Problem Interviewers Are Testing

- How does one service failure propagate through the system?
- What mechanisms prevent one failure from taking down everything?
- Can you design for partial failure?

---

## 3. Key Concepts

### What is a Cascading Failure?

A failure in one component that triggers failures in dependent components, which in turn trigger more failuresâ€”a domino effect.

```
ONE SERVICE SLOWS DOWN:
Service A (slow) â†’ Service B waits â†’ B's threads exhausted
                                   â†’ Service C calls B â†’ C waits
                                   â†’ Thread pools everywhere exhausted
                                   â†’ Full system outage

A small delay in one service â†’ Complete system failure
```

### Common Triggers

- **Resource exhaustion**: Thread pools, connections, memory
- **Timeout propagation**: Slow service â†’ timeout â†’ retry â†’ more load
- **Circuit without breaker**: Keep calling failing service
- **Shared dependencies**: Shared DB/cache fails â†’ everything fails

---

## 4. Mitigation Strategies

### 1. Circuit Breakers

Stop calling a failing service, fail fast instead.

```
States: CLOSED â†’ OPEN â†’ HALF-OPEN

CLOSED: Normal operation
        â”‚ failure_count > threshold
        â–¼
OPEN:   Fail immediately (don't call service)
        â”‚ after timeout
        â–¼
HALF-OPEN: Try one request
        â”‚ if success â†’ CLOSED
        â”‚ if failure â†’ OPEN
```

### 2. Bulkheads

Isolate components so failure in one doesn't exhaust shared resources.

```
WITHOUT BULKHEAD:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Shared Thread Pool (100)   â”‚
â”‚  Service A + B + C all share   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
A is slow â†’ uses all 100 â†’ B and C starved

WITH BULKHEAD:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   A    â”‚ â”‚   B    â”‚ â”‚   C    â”‚
â”‚  (33)  â”‚ â”‚  (33)  â”‚ â”‚  (33)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
A is slow â†’ uses its 33 â†’ B and C unaffected
```

### 3. Timeouts (Aggressive)

Bound the damage from slow dependencies.

```
Rule of Thumb:
â”œâ”€â”€ Database: 500ms timeout
â”œâ”€â”€ Cache: 50ms timeout  
â”œâ”€â”€ Inter-service: 1-2s timeout
â””â”€â”€ External API: 3-5s timeout

Timeout = Expected P99 Ã— 2 (with buffer)
```

### 4. Load Shedding

Intentionally drop requests when overloaded.

```python
def handle_request(request):
    if cpu_usage > 80% or queue_depth > 1000:
        if request.priority < HIGH:
            return 503  # Shed load
    
    return process(request)
```

---

## 5. Architecture Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API Gateway                    â”‚
â”‚   (rate limit, circuit breaker, timeout: 5s)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼            â–¼            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Service Aâ”‚  â”‚Service Bâ”‚  â”‚Service Câ”‚
    â”‚ bulkheadâ”‚  â”‚ bulkheadâ”‚  â”‚ bulkheadâ”‚
    â”‚ timeout â”‚  â”‚ timeout â”‚  â”‚ timeout â”‚
    â”‚ circuit â”‚  â”‚ circuit â”‚  â”‚ circuit â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚            â”‚            â”‚
         â”‚       â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”       â”‚
         â””â”€â”€â”€â”€â”€â”€â–ºâ”‚   DB    â”‚â—„â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ (pooled)â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Trade-offs

| Strategy | Pro | Con |
|----------|-----|-----|
| **Circuit breaker** | Prevents hammering | May reject good requests |
| **Bulkhead** | Isolation | Reduced total capacity |
| **Aggressive timeout** | Bounds latency | May timeout valid slow queries |
| **Load shedding** | System survives | Dropped requests |

---

## 7. Interview Explanation

> "To prevent cascading failures, I'd implement defense in depth. First, each service has dedicated thread pools (bulkheads) so a slow dependency can't starve other operations.
>
> Second, all external calls have circuit breakers. If Service B's error rate exceeds 50%, we stop calling it and fail fast with a fallback response. This prevents querying a failing service and making things worse.
>
> Third, aggressive timeouts bound how long any request can wait. P99 plus 20% buffer. If we don't get a response, we timeout and return an error rather than blocking threads indefinitely.
>
> The trade-off is sometimes we fail requests that would have succeeded. But failing fast keeps the system responsive for the majority of users."

---

## 8. Common Mistakes

- **No timeouts**: "Wait for DB" â†’ Threads blocked forever
- **Shared thread pools**: "It's simpler" â†’ One slow service blocks all
- **No circuit breakers**: "Keep trying" â†’ Overloads failing service
- **Retry without backoff**: "Retry immediately" â†’ Amplifies load

---

## 9. Senior-Level Phrases

- "Bulkheads isolate failure domains so a slow dependency only affects its consumers."
- "Circuit breakers prevent cascading load onto already-failing services."
- "I'd set timeouts based on P99 latency with 20% buffer for tail cases."
- "Load shedding protects the system at the cost of some dropped requests."
